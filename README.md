# Aulas-DIO
## Aprendendo e Usando o Azure Data Factory

### Como funciona o processo

- **Conectar e copiar dados:** É possivel conectar várias fontes (banco, arquivos, nuvem) e copiar os dados para um lugar só, exemplo: Azure Blob ou Data Lake.
  
- **Transformar dados:** Pode-se  utilizar fluxos visuais (sem código) para limpar, juntar e modificar dados. Também pode rodar scripts em Spark, se quiser.

- **Orquestrar etapas:** Montar o passo a passo do processo, com atividades que rodam em sequência ou paralelas, controlando tudo direitinho.
  
- **Publicar e monitorar:** Depois de criar, publica e acompanha o que está rodando pelo portal, vendo erros e tempo de execução.

### O que achei interessante

- Montar uma linha de produção dos dados, tudo bem organizado e automático.  
- Dá pra fazer transformações complexas sem precisar programar, só arrastando e configurando.  
- Integra fácil com outras ferramentas do Azure, como Synapse, e ajuda muito em projetos grandes.  
- O monitoramento é bem completo, então fica fácil saber se algo deu errado.

### Possibilidades legais

- Migrar dados de sistemas antigos para a nuvem com segurança.  
- Criar pipelines para alimentar data warehouses e relatórios.  
- Trabalhar com dados grandes e variados no Data Lake.  
- Automatizar tudo, com gatilhos e integração com Git para versionar os pipelines.
